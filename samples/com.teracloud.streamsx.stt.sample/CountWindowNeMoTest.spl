namespace com.teracloud.streamsx.stt.sample;

use com.teracloud.streamsx.stt::*;

/**
 * Count-based Window NeMo Test
 * 
 * Uses a count-based window to trigger transcription every 10 audio chunks.
 * This should be more reliable than time-based windows.
 */
composite CountWindowNeMoTest {
    graph
        // Audio source - reads from test file
        stream<blob audioChunk, uint64 audioTimestamp> AudioStream = FileAudioSource() {
            param
                filename: "/homes/jsharpe/teracloud/toolkits/com.teracloud.streamsx.stt/test_data/audio/librispeech-1995-1837-0001.wav";
                blockSize: 16384u;  // 1 second chunks
                sampleRate: 16000;
                bitsPerSample: 16;
                channelCount: 1;
        }
        
        // Debug: Show audio flow
        () as AudioDebug = Custom(AudioStream) {
            logic
                state: {
                    mutable int32 chunkCount = 0;
                }
                onTuple AudioStream: {
                    chunkCount++;
                    printStringLn("Audio chunk " + (rstring)chunkCount + ": " + 
                                 (rstring)size(audioChunk) + " bytes");
                }
                onPunct AudioStream: {
                    printStringLn("Punctuation received: " + (rstring)currentPunct());
                }
        }
        
        // Add count-based tumbling window - every 10 chunks
        stream<blob audioChunk, uint64 audioTimestamp> WindowedAudio = 
            Aggregate(AudioStream) {
                window
                    AudioStream: tumbling, count(10);  // Window every 10 chunks
                output
                    WindowedAudio: 
                        audioChunk = Last(audioChunk),
                        audioTimestamp = Last(audioTimestamp);
            }
        
        // Debug windowed stream
        () as WindowDebug = Custom(WindowedAudio) {
            logic
                onTuple WindowedAudio: {
                    printStringLn(">>> Window closed! Sending audio chunk to NeMoSTT");
                }
                onPunct WindowedAudio: {
                    printStringLn(">>> Window punctuation: " + (rstring)currentPunct());
                }
        }
        
        // NeMo speech recognition
        stream<rstring transcription> Transcription = NeMoSTT(WindowedAudio) {
            param
                modelPath: "/homes/jsharpe/teracloud/toolkits/com.teracloud.streamsx.stt/models/fastconformer_ctc_export/model.onnx";
                tokensPath: "/homes/jsharpe/teracloud/toolkits/com.teracloud.streamsx.stt/models/fastconformer_ctc_export/tokens_with_ids.txt";
        }
        
        // Display transcription results
        () as Display = Custom(Transcription) {
            logic
                state: {
                    mutable int32 transcriptionCount = 0;
                }
                onTuple Transcription: {
                    transcriptionCount++;
                    printStringLn("=========================================");
                    printStringLn("âœ… TRANSCRIPTION #" + (rstring)transcriptionCount + ":");
                    printStringLn(transcription);
                    printStringLn("=========================================");
                }
        }
        
        // Save transcription to file
        () as FileWriter = FileSink(Transcription) {
            param
                file: "CountWindowNeMoTest_transcript_" + (rstring)getTimestampInSecs() + ".txt";
                format: txt;
        }
}